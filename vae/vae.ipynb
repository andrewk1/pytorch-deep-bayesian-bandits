{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='VAE MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "\n",
    "batch_size=128\n",
    "epochs=10\n",
    "log_interval=100\n",
    "seed=1\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 118.621101\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 110.434624\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 113.340065\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 116.755386\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 108.267685\n",
      "====> Epoch: 1 Average loss: 114.6074\n",
      "====> Test set loss: 111.8555\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 111.358978\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 107.061127\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 114.494041\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 106.754814\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 114.545807\n",
      "====> Epoch: 2 Average loss: 111.5671\n",
      "====> Test set loss: 109.5794\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 104.894104\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 107.635330\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 107.619278\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 108.788017\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 109.550995\n",
      "====> Epoch: 3 Average loss: 109.7161\n",
      "====> Test set loss: 108.2817\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 111.057968\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 108.447113\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 105.538864\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 110.529938\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 107.780357\n",
      "====> Epoch: 4 Average loss: 108.5616\n",
      "====> Test set loss: 107.2628\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 107.799126\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 107.180191\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 107.910141\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 107.730026\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 108.145279\n",
      "====> Epoch: 5 Average loss: 107.6640\n",
      "====> Test set loss: 106.5994\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 105.795929\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 109.453262\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 105.878433\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 109.378891\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 105.838676\n",
      "====> Epoch: 6 Average loss: 107.0637\n",
      "====> Test set loss: 106.4613\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 103.686554\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 103.570465\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 110.935463\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 103.209160\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 106.510376\n",
      "====> Epoch: 7 Average loss: 106.5672\n",
      "====> Test set loss: 105.9486\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 107.630875\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 105.146294\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 107.965858\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 108.859200\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 110.050674\n",
      "====> Epoch: 8 Average loss: 106.1023\n",
      "====> Test set loss: 105.2162\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 103.912415\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 100.805275\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 106.777847\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 105.661392\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 104.252655\n",
      "====> Epoch: 9 Average loss: 105.7688\n",
      "====> Test set loss: 105.0996\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 107.234230\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 103.988243\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 102.737694\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 102.708252\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 102.763290\n",
      "====> Epoch: 10 Average loss: 105.4422\n",
      "====> Test set loss: 105.0137\n"
     ]
    }
   ],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, 20).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(64, 1, 28, 28),\n",
    "                   'results/sample_' + str(epoch) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0002, -0.0345, -0.0009,  ..., -0.0027, -0.0115,  0.0214],\n",
       "        [ 0.0353,  0.0217, -0.0138,  ...,  0.0175, -0.0148, -0.0144],\n",
       "        [-0.0323,  0.0176,  0.0317,  ...,  0.0139,  0.0229,  0.0055],\n",
       "        ...,\n",
       "        [ 0.0230,  0.0242, -0.0216,  ..., -0.0272, -0.0094,  0.0178],\n",
       "        [-0.0018, -0.0211, -0.0226,  ...,  0.0227, -0.0001,  0.0340],\n",
       "        [-0.0074,  0.0116, -0.0033,  ...,  0.0298, -0.0254,  0.0352]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['fc1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {139626076512192: {'step': 5628,\n",
       "   'exp_avg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       "   'exp_avg_sq': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]])},\n",
       "  139626076509096: {'step': 5628,\n",
       "   'exp_avg': tensor([ 2.7874e+00,  5.6052e-45, -1.0496e+00,  4.8892e-02,  2.8884e+00,\n",
       "            2.6043e+00,  2.1176e-01, -1.9953e+00,  5.6052e-45, -1.5005e+00,\n",
       "           -1.3496e-01,  5.6052e-45,  1.2239e+00,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  1.1401e+00, -1.3474e+00,  3.9741e+00,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  1.3886e+00, -1.5822e+00,  5.6052e-45,\n",
       "            5.6052e-45, -4.0975e+00,  1.8905e+00, -1.5684e-01,  5.6052e-45,\n",
       "           -1.3633e-01,  1.5732e+00,  5.6052e-45,  5.6591e-01, -1.3644e+00,\n",
       "            5.6052e-45,  7.2124e-01,  5.6052e-45, -3.3296e-01, -1.5883e-01,\n",
       "           -4.2069e+00,  5.6052e-45, -5.6802e-01,  5.6052e-45,  5.6052e-45,\n",
       "           -5.6974e-01,  3.2996e+00, -4.3929e+00, -5.4643e-01, -1.8430e+00,\n",
       "            5.6052e-45, -9.0981e-01,  5.6052e-45,  5.6052e-45, -4.0118e+00,\n",
       "           -1.3229e+00, -2.4045e-01, -3.6379e-01, -4.3271e-01,  5.6052e-45,\n",
       "            1.8772e+00,  7.5421e-01,  1.1985e+00,  5.6052e-45,  1.6003e-01,\n",
       "           -4.3726e+00,  5.6052e-45,  2.5826e-02,  2.5961e+00,  5.6052e-45,\n",
       "           -8.8311e-01,  5.6863e-01,  2.0390e+00, -1.8789e+00,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45, -3.6451e+00,  5.6052e-45,  5.6052e-45,\n",
       "            8.4374e+00,  1.0114e+00,  5.6052e-45,  2.4747e+00, -2.6984e+00,\n",
       "            4.1640e-01,  5.6052e-45,  5.6052e-45,  5.6052e-45,  1.5213e+00,\n",
       "            1.0122e+00,  1.7445e+00,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "            5.6052e-45,  1.8278e+00, -9.2623e-02,  2.8889e+00,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  3.6308e+00,  1.3997e+00,  5.6052e-45,\n",
       "            1.1067e+00, -1.7556e+00, -9.5489e-01,  2.2681e+00,  5.6052e-45,\n",
       "            5.6052e-45,  3.0097e+00,  1.3379e+00, -3.2167e+00, -5.4596e-03,\n",
       "            2.9827e+00, -5.7762e+00,  5.6052e-45,  6.9430e-01, -3.9569e-01,\n",
       "            5.6052e-45,  5.6052e-45, -1.4129e+00,  2.6488e+00,  5.6052e-45,\n",
       "            5.6052e-45, -1.0165e+00,  6.0530e-01, -6.7192e-01,  1.3215e+00,\n",
       "           -3.4770e+00,  2.4147e-01,  5.6052e-45,  3.6154e+00, -6.3540e+00,\n",
       "           -6.9988e-01,  2.8230e-01,  5.6052e-45,  2.3406e-01,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45, -6.6570e+00,  5.6052e-45, -1.4621e+00,\n",
       "            5.6052e-45,  2.8301e-01,  2.7540e+00,  3.0805e-01,  5.6052e-45,\n",
       "            2.7634e+00,  5.6052e-45,  5.6052e-45,  5.6052e-45, -2.4291e+00,\n",
       "           -1.9604e+00,  5.6052e-45,  5.6052e-45,  4.7092e-02, -4.5065e+00,\n",
       "           -1.4764e+00,  5.6052e-45,  2.3610e-01,  1.1758e-03,  5.6052e-45,\n",
       "           -1.5042e+00, -2.8437e-01, -1.5857e-01,  5.6052e-45,  4.5548e-01,\n",
       "           -1.7703e+00,  5.6052e-45,  5.6052e-45, -1.4645e+00,  5.6052e-45,\n",
       "           -1.1662e+00,  7.9443e-01, -8.9163e-01,  1.8419e-01,  2.4572e+00,\n",
       "            5.6052e-45,  5.6052e-45, -6.7484e-01,  9.8966e-01,  2.0474e-01,\n",
       "            5.6052e-45,  6.4524e-01, -4.9059e+00,  4.9123e+00,  1.9274e+00,\n",
       "           -2.6590e+00, -3.0526e+00, -1.9993e+00,  7.4800e+00,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  7.1782e+00,\n",
       "           -2.4390e+00, -6.2122e-02,  5.6052e-45,  5.6052e-45,  2.6258e+00,\n",
       "           -2.1174e+00,  5.6052e-45,  7.5629e-01, -6.8080e-01,  1.5562e+00,\n",
       "           -3.5453e+00, -6.3111e-01,  5.6052e-45,  5.6052e-45,  5.9741e-01,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
       "           -8.3253e-01, -1.7377e+00,  5.6052e-45,  3.8656e+00, -4.4456e+00,\n",
       "           -4.7494e-01, -2.6762e+00, -2.0368e+00,  5.6052e-45,  5.6052e-45,\n",
       "           -3.7353e+00,  5.6052e-45, -5.2174e-01, -1.8049e+00, -1.3901e+00,\n",
       "            5.6052e-45,  2.5286e-01,  5.6052e-45,  9.1573e-01,  5.6052e-45,\n",
       "            5.6052e-45,  2.6653e+00, -2.1072e+00,  2.9648e+00, -7.9886e-01,\n",
       "            1.9962e+00,  5.6052e-45, -1.5424e+00, -4.6433e-01, -7.6624e-01,\n",
       "            5.6052e-45,  1.4211e+00,  5.6052e-45,  5.6052e-45, -8.5781e-01,\n",
       "           -1.9735e-02,  1.1922e+00,  5.6052e-45, -3.6284e+00, -2.8678e-01,\n",
       "            1.3577e+00,  5.6052e-45, -1.3066e+00,  5.6052e-45,  4.7699e-01,\n",
       "            2.7767e-02,  7.7842e-01,  5.6052e-45,  1.0289e+00, -8.6852e-01,\n",
       "            2.6960e+00, -1.0678e+00, -3.0552e+00,  4.1627e-01,  1.9779e+00,\n",
       "            7.4316e-01, -1.4127e+00,  8.9342e-01, -7.8939e-01, -8.3299e-01,\n",
       "            5.6052e-45,  7.4809e-01, -9.2572e-03,  6.4772e-01,  1.2625e+00,\n",
       "            5.6052e-45,  1.4602e+00, -7.7586e-01, -3.2406e-01,  1.5598e+00,\n",
       "           -2.9132e-01, -2.3096e+00,  5.7403e-02,  5.6052e-45, -2.0158e+00,\n",
       "            5.6052e-45,  2.9569e+00,  5.6052e-45,  5.6052e-45, -1.6829e-01,\n",
       "            4.8588e+00, -4.2107e-01,  5.6052e-45,  5.6052e-45,  3.2263e+00,\n",
       "            5.0661e-01, -5.2818e-01, -5.4253e-01, -1.7952e+00, -1.4936e+00,\n",
       "           -2.4916e+00,  5.6052e-45,  5.6052e-45,  2.6139e+00,  5.6052e-45,\n",
       "            2.4894e+00, -1.9195e+00, -1.6742e+00, -1.4325e+00,  5.6052e-45,\n",
       "           -7.7365e+00,  1.7714e+00,  5.6052e-45,  5.6052e-45, -2.8875e+00,\n",
       "            5.6052e-45,  5.6052e-45,  5.6052e-45,  1.7847e+00, -5.3610e-01,\n",
       "            5.6052e-45, -1.0026e+00, -1.5841e-01,  5.6052e-45, -7.7985e-01,\n",
       "            5.6052e-45, -8.9527e-01,  5.6052e-45,  5.6052e-45, -2.3785e+00,\n",
       "           -2.0566e-01, -1.5971e+00, -5.1441e-01, -3.4737e+00,  5.6052e-45,\n",
       "           -9.2115e-01,  5.0953e-01,  5.6052e-45,  9.8896e-01,  5.6052e-45,\n",
       "            5.6052e-45,  5.6052e-45,  3.3468e-01,  5.6052e-45,  5.6052e-45,\n",
       "           -4.8078e-01, -8.3844e-01, -1.1663e+00,  5.6052e-45, -1.5538e+00,\n",
       "            1.1430e+01, -2.7538e+00,  1.6690e+00, -1.7067e+00,  5.6052e-45,\n",
       "            2.8178e+00,  6.8029e-02,  5.6052e-45, -5.9963e-01,  2.1096e-01,\n",
       "           -1.1412e+00,  5.6052e-45,  1.4775e+00,  2.9668e+00,  5.6052e-45,\n",
       "            6.8563e-01, -8.7966e+00, -1.5102e+00,  5.6052e-45,  1.6593e-01,\n",
       "            4.6222e-02,  5.6052e-45,  2.7627e-01,  5.6052e-45, -5.2402e+00,\n",
       "            5.6052e-45,  1.5490e+00,  1.1825e+00,  2.3013e+00,  5.6052e-45,\n",
       "           -9.0118e-01,  5.6052e-45,  5.6052e-45,  1.2004e+00, -1.0999e+00,\n",
       "           -1.5716e+00,  5.6052e-45, -2.5928e+00,  1.2974e+00,  5.6052e-45]),\n",
       "   'exp_avg_sq': tensor([1.5925e+02, 3.6810e-03, 4.1014e+02, 1.5848e+02, 5.6701e+01, 5.6979e+01,\n",
       "           4.4110e+01, 1.1853e+02, 1.7457e-04, 1.8514e+02, 3.2135e+01, 8.2952e-06,\n",
       "           3.7518e+01, 4.7894e-04, 7.6299e-04, 5.3548e-03, 1.8393e+02, 2.3920e+02,\n",
       "           2.0035e+02, 1.6630e-04, 3.2930e-04, 2.4428e-04, 4.7357e+01, 6.3644e+01,\n",
       "           2.5985e-05, 1.5034e-04, 1.1998e+02, 3.6080e+02, 1.0672e+03, 2.6137e-05,\n",
       "           1.8305e+02, 2.8882e+02, 1.5862e-04, 3.5446e+02, 7.3579e+01, 1.3011e-03,\n",
       "           5.0768e+01, 4.5706e-03, 8.3420e+02, 1.6813e+00, 1.6719e+02, 2.3163e-04,\n",
       "           9.9952e+01, 8.2884e-03, 1.2742e-04, 8.9189e+00, 1.7767e+02, 6.2477e+02,\n",
       "           9.6356e+01, 6.9762e+01, 4.6637e-05, 2.6664e+02, 5.5231e-03, 6.2759e-05,\n",
       "           5.4317e+02, 1.2981e+02, 5.1856e+01, 8.5208e+01, 3.8834e+01, 8.8427e-04,\n",
       "           9.9250e+01, 1.1774e+02, 7.3829e+01, 4.4574e-03, 1.8805e+02, 2.4714e+02,\n",
       "           1.1015e-06, 1.2079e+02, 3.7581e+02, 1.4903e-03, 8.6897e+02, 1.0935e+02,\n",
       "           1.1280e+02, 6.5677e+01, 1.2521e-03, 6.7838e-05, 1.1934e-05, 1.9448e+02,\n",
       "           2.2697e-02, 4.8526e-04, 5.3515e+02, 4.4576e+01, 2.1400e-04, 2.7310e+02,\n",
       "           1.3326e+02, 8.0258e+01, 2.0190e-03, 5.7239e-05, 1.3053e-03, 1.3335e+02,\n",
       "           2.7118e+02, 3.9170e+01, 4.3908e-04, 3.4725e-03, 1.6398e-02, 4.5481e-04,\n",
       "           2.1949e+02, 2.9606e-01, 3.3213e+02, 3.7815e-03, 2.5309e-03, 1.9429e-05,\n",
       "           1.0284e+03, 7.1579e+01, 1.2134e-02, 1.2358e+02, 1.5101e+02, 7.6593e+01,\n",
       "           1.5631e+02, 1.3016e-05, 1.7129e-04, 1.2516e+02, 1.0085e+02, 1.3140e+03,\n",
       "           4.3100e+01, 7.4404e+01, 7.3113e+02, 3.6306e-04, 9.4621e+01, 5.8686e+02,\n",
       "           5.3182e-05, 3.0292e-04, 1.0922e+02, 3.2523e+02, 4.0637e-06, 2.4447e-03,\n",
       "           8.1330e+01, 6.3296e+01, 4.2615e+00, 7.9327e+01, 4.9466e+02, 1.8518e+02,\n",
       "           2.1344e-02, 1.4456e+02, 1.3078e+03, 2.5805e+02, 8.3625e+01, 2.2075e-05,\n",
       "           1.3570e+02, 1.0095e-04, 3.1737e-04, 8.0972e-04, 5.5595e+02, 3.3284e-04,\n",
       "           6.1668e+01, 1.1361e-04, 1.2620e+02, 1.7305e+02, 1.9495e+02, 1.9495e-05,\n",
       "           1.7267e+02, 2.3656e-04, 1.9087e-04, 3.0952e-03, 6.0187e+02, 2.3229e+02,\n",
       "           1.4677e-04, 5.9673e-05, 1.5226e+02, 1.0433e+02, 1.2235e+02, 3.9153e-04,\n",
       "           7.1999e+01, 6.4344e+01, 2.4461e-05, 6.1968e+02, 5.9585e+01, 1.4022e+02,\n",
       "           2.1585e-05, 8.5147e+01, 2.2893e+02, 8.1271e-05, 5.8062e-04, 6.4739e+01,\n",
       "           1.0157e-04, 7.9052e+01, 2.2013e+02, 8.2227e+01, 8.7278e+01, 1.1940e+02,\n",
       "           5.0797e-03, 1.2466e-04, 7.8332e+01, 3.5556e+02, 1.1791e+02, 1.7563e-04,\n",
       "           6.8575e+02, 4.8498e+02, 5.6718e+02, 2.4408e+02, 4.5437e+02, 2.5037e+02,\n",
       "           8.0373e+01, 9.5202e+02, 1.0220e-04, 1.9683e-02, 2.1491e-04, 1.3567e-03,\n",
       "           9.6340e-04, 3.9750e+02, 1.0531e+02, 1.2460e+02, 7.0056e-05, 1.2100e-06,\n",
       "           1.2245e+02, 7.2517e+01, 6.2121e-02, 5.2559e+01, 6.1666e+01, 1.2794e+02,\n",
       "           8.5654e+01, 4.2357e+01, 1.3984e-05, 4.6761e-03, 1.2086e+02, 4.9987e-04,\n",
       "           2.2333e-02, 1.4267e-02, 4.8697e-06, 3.0877e-04, 1.1411e+02, 1.5737e+02,\n",
       "           2.5051e-03, 5.7649e+02, 9.0387e+02, 3.8941e+01, 7.8279e+01, 1.8974e+02,\n",
       "           1.0459e-04, 3.9151e-05, 3.4267e+02, 5.4800e-04, 5.6014e+01, 2.7406e+02,\n",
       "           1.5326e+01, 1.1129e-04, 1.7466e+02, 8.9873e-05, 8.8765e+01, 1.0030e-02,\n",
       "           2.3757e-04, 1.7340e+02, 7.1854e+01, 7.2266e+01, 4.7728e+01, 6.4032e+02,\n",
       "           6.2421e-05, 9.7025e+01, 1.3250e+02, 8.8727e+01, 9.8474e-05, 1.6807e+02,\n",
       "           7.9745e-05, 1.2729e-05, 2.1896e+02, 3.9500e+02, 5.8963e+01, 7.7809e-03,\n",
       "           2.6024e+02, 7.5893e+01, 4.5950e+01, 6.8394e-06, 5.6995e+01, 2.9472e-03,\n",
       "           4.1871e+01, 4.6985e+01, 2.2979e+02, 1.3913e-05, 8.0832e+01, 3.5536e+01,\n",
       "           8.8421e+01, 3.8163e+02, 8.1834e+01, 1.4739e+02, 1.3136e+02, 1.1818e+02,\n",
       "           5.0810e+01, 2.5768e+02, 1.1148e+02, 9.6672e+01, 1.6309e-02, 6.5431e+01,\n",
       "           6.9953e+01, 1.3704e+02, 2.0338e+02, 1.0300e-03, 1.2581e+02, 5.9039e+01,\n",
       "           4.7266e+01, 1.5724e+02, 1.3536e+02, 1.3888e+02, 8.7124e+02, 1.6612e-04,\n",
       "           8.0057e+02, 1.0651e-02, 4.1071e+01, 4.6288e-04, 1.1438e-04, 1.7316e+02,\n",
       "           6.1080e+02, 3.1914e+00, 1.9034e-05, 1.2265e-04, 3.9397e+02, 2.0712e+02,\n",
       "           1.7875e+02, 2.2797e+02, 7.2064e+01, 1.9416e+02, 1.3267e+02, 8.1389e-04,\n",
       "           1.0009e-04, 9.0107e+01, 5.4305e-04, 1.2283e+02, 1.2874e+02, 1.0565e+02,\n",
       "           5.0347e+01, 1.8069e-05, 4.3204e+02, 7.9477e+01, 4.9561e-04, 1.5351e-03,\n",
       "           6.2640e+01, 7.9435e-04, 2.6893e-05, 5.9077e-04, 3.5327e+01, 2.0800e+02,\n",
       "           6.4872e-03, 1.2162e+02, 5.4786e+01, 3.3672e-04, 4.9006e+02, 1.0763e-03,\n",
       "           8.5691e+01, 9.4884e-05, 4.3467e-04, 9.3420e+01, 5.5490e+01, 4.6313e+01,\n",
       "           9.1794e+01, 7.9726e+02, 5.2334e-04, 3.1776e+01, 5.2250e+01, 3.4977e-02,\n",
       "           5.1755e+01, 1.6402e-04, 1.7264e-03, 5.7320e-04, 7.3562e+00, 1.2985e-03,\n",
       "           1.3573e-03, 3.8028e+02, 1.0564e+02, 7.3273e+01, 2.0117e-03, 5.3689e+01,\n",
       "           5.0240e+02, 1.8550e+02, 4.2529e+01, 1.8874e+02, 4.4543e-03, 2.0512e+02,\n",
       "           8.8558e+01, 5.2965e-04, 1.6570e+02, 5.5236e+01, 7.8500e+01, 2.8369e-03,\n",
       "           1.7458e+01, 1.0921e+02, 1.4985e-05, 2.3432e+01, 5.2427e+02, 5.9505e+01,\n",
       "           1.3518e-03, 1.1502e+02, 9.7949e-01, 3.4737e-02, 1.0243e+02, 4.4020e-03,\n",
       "           2.7796e+02, 1.1502e-03, 7.7782e+01, 1.0208e+02, 9.6695e+01, 1.1833e-03,\n",
       "           3.0588e+01, 7.8429e-04, 8.0767e-03, 4.9706e+02, 8.1171e+01, 8.4430e+01,\n",
       "           1.0468e-03, 7.1152e+02, 1.1272e+02, 2.0546e-02])},\n",
       "  139626076558320: {'step': 5628,\n",
       "   'exp_avg': tensor([[ 1.4402e+00, -5.6052e-45, -2.1958e+00,  ..., -1.0983e+00,\n",
       "             2.0359e+00,  5.6052e-45],\n",
       "           [ 2.9988e+00,  5.6052e-45,  4.6591e+01,  ...,  1.7879e+01,\n",
       "             8.6144e+00, -5.6052e-45],\n",
       "           [-2.2266e+01, -5.6052e-45, -2.0627e+00,  ..., -1.0571e+01,\n",
       "            -2.2498e+00,  5.6052e-45],\n",
       "           ...,\n",
       "           [ 8.7091e+00,  5.6052e-45,  1.5146e+01,  ...,  5.3957e+00,\n",
       "             3.4790e+00, -5.6052e-45],\n",
       "           [ 1.2828e+01,  5.6052e-45,  2.9210e+01,  ...,  1.5591e+01,\n",
       "             8.7813e+00, -5.6052e-45],\n",
       "           [-2.4662e+00, -5.6052e-45, -3.2210e+00,  ...,  1.8400e+00,\n",
       "             1.9215e-01,  5.6052e-45]]),\n",
       "   'exp_avg_sq': tensor([[1.1253e+03, 6.7617e-03, 3.2373e+03,  ..., 1.3894e+03, 1.8340e+02,\n",
       "            5.6390e-03],\n",
       "           [5.9071e+03, 5.5024e-04, 1.7569e+04,  ..., 8.7269e+03, 1.1505e+03,\n",
       "            2.8730e-03],\n",
       "           [9.3906e+03, 1.5121e-04, 3.0639e+04,  ..., 1.3146e+04, 2.0273e+03,\n",
       "            6.4880e-04],\n",
       "           ...,\n",
       "           [2.8008e+03, 2.5470e-04, 8.9629e+03,  ..., 3.6478e+03, 4.5638e+02,\n",
       "            2.5124e-03],\n",
       "           [5.8803e+03, 1.1909e-03, 1.8276e+04,  ..., 7.9189e+03, 1.1637e+03,\n",
       "            1.0036e-03],\n",
       "           [1.1291e+03, 3.5241e-03, 3.4156e+03,  ..., 1.4535e+03, 1.8890e+02,\n",
       "            6.5962e-03]])},\n",
       "  139626076560048: {'step': 5628,\n",
       "   'exp_avg': tensor([  1.6448,  26.1373, -18.5529, -10.3801,  -1.5101, -15.9493,   1.4288,\n",
       "            13.1336,  23.1581,  -7.8413,  -1.3275,  -5.8578,  51.6456,   8.8185,\n",
       "           -17.1601,  28.8976,  14.0376,  15.9391,  16.9806,   1.7576]),\n",
       "   'exp_avg_sq': tensor([ 2340.9407, 14409.2002, 22346.9492,  8078.2861,  4153.8398,  6331.8823,\n",
       "            2230.2327,  3292.8643, 30252.5781,  3809.9045, 14004.5205, 10384.0908,\n",
       "           52591.8906,   900.9979, 24291.5137,  7600.6304,  8904.6572,  6480.2842,\n",
       "           13639.5186,  2636.9202])},\n",
       "  139626076558896: {'step': 5628,\n",
       "   'exp_avg': tensor([[ 1.0357e+00, -5.6052e-45,  1.3007e+00,  ..., -1.7404e+00,\n",
       "            -3.0563e-01,  5.6052e-45],\n",
       "           [ 5.3356e-01, -5.6052e-45, -1.4425e+00,  ..., -2.1805e+00,\n",
       "            -2.5013e-01,  5.6052e-45],\n",
       "           [-3.8522e+00, -5.6052e-45, -3.4670e+00,  ..., -1.9086e-01,\n",
       "             2.5056e-01,  5.6052e-45],\n",
       "           ...,\n",
       "           [-1.2334e+00, -5.6052e-45, -6.0531e-01,  ..., -1.4909e+00,\n",
       "             1.9651e+00,  5.6052e-45],\n",
       "           [ 5.7278e-01, -5.6052e-45,  2.9024e+00,  ...,  3.4525e+00,\n",
       "             3.1242e+00,  5.6052e-45],\n",
       "           [-9.6308e-01, -5.6052e-45, -2.0890e+00,  ..., -2.5406e-01,\n",
       "            -6.4342e-01, -5.6052e-45]]),\n",
       "   'exp_avg_sq': tensor([[5.2389e+01, 3.3612e-03, 1.3413e+02,  ..., 7.0715e+01, 1.5693e+01,\n",
       "            3.1890e-03],\n",
       "           [6.1178e+01, 1.7571e-03, 1.5618e+02,  ..., 8.7689e+01, 2.0906e+01,\n",
       "            9.1743e-04],\n",
       "           [6.6084e+01, 2.4747e-03, 1.7391e+02,  ..., 9.7205e+01, 2.2480e+01,\n",
       "            6.0261e-03],\n",
       "           ...,\n",
       "           [5.7347e+01, 3.0228e-03, 1.4122e+02,  ..., 7.9266e+01, 1.7789e+01,\n",
       "            1.1905e-03],\n",
       "           [6.5536e+01, 3.1351e-03, 1.5144e+02,  ..., 8.5753e+01, 2.0986e+01,\n",
       "            4.3266e-03],\n",
       "           [5.0319e+01, 1.8989e-03, 1.2255e+02,  ..., 6.6478e+01, 1.4699e+01,\n",
       "            3.2837e-04]])},\n",
       "  139626076559040: {'step': 5628,\n",
       "   'exp_avg': tensor([ 0.6926, -1.5123, -3.3697,  0.4740, -1.6511,  0.1012, -1.5486, -0.3666,\n",
       "            2.7008,  4.0234, -3.8191, -0.8531, -1.0675, -1.6221, -0.9322, -2.4742,\n",
       "           -0.5601, -1.8350,  2.5334, -0.3640]),\n",
       "   'exp_avg_sq': tensor([ 95.6522, 112.4618, 129.1682, 104.1070, 102.5127, 107.0365,  87.5516,\n",
       "           105.8234, 122.7736,  96.1210, 120.8125, 113.7536, 136.3064,  67.4330,\n",
       "           122.7557, 109.4286, 104.0835, 107.2924, 114.1051,  92.3878])},\n",
       "  139626076559328: {'step': 5628,\n",
       "   'exp_avg': tensor([[ 1.3339, -0.9431, -0.5895,  ..., -1.9979, -0.6656, -0.7527],\n",
       "           [ 1.3287, -4.6026, -0.6423,  ..., -1.6792, -0.8331,  1.5104],\n",
       "           [ 0.5446, -1.6109,  0.1778,  ..., -1.0368, -0.6425, -1.0826],\n",
       "           ...,\n",
       "           [ 0.1741,  0.7310, -0.6867,  ..., -0.7498,  1.1610, -0.4123],\n",
       "           [-0.3166, -0.3127,  0.4792,  ...,  2.0617,  0.7778, -1.0307],\n",
       "           [ 0.6005,  2.5632,  1.5383,  ..., -0.4942,  1.4441, -0.5390]]),\n",
       "   'exp_avg_sq': tensor([[32.7156, 32.6007, 39.2308,  ..., 34.6236, 39.8157, 34.3841],\n",
       "           [59.1856, 61.2382, 69.6735,  ..., 63.1416, 69.3130, 61.3739],\n",
       "           [13.5802, 15.4343, 17.0903,  ..., 14.6616, 16.4557, 15.5736],\n",
       "           ...,\n",
       "           [29.8682, 30.0886, 33.3609,  ..., 34.0946, 33.9516, 29.4084],\n",
       "           [40.2634, 46.4911, 39.6570,  ..., 39.5350, 40.8550, 37.5795],\n",
       "           [47.5132, 58.4583, 46.4165,  ..., 40.7751, 49.7627, 50.2417]])},\n",
       "  139626076559472: {'step': 5628,\n",
       "   'exp_avg': tensor([-7.9268e-01, -9.0685e-01,  4.5805e-01, -4.7156e-01,  6.3029e-01,\n",
       "           -8.7892e-01, -1.9357e+00, -4.7964e-02,  4.1585e-02, -1.4211e+00,\n",
       "            1.7175e-01,  7.8343e-02,  9.8056e-02,  1.9297e-01,  2.4223e-01,\n",
       "           -6.3643e-01, -1.1759e-01, -1.4506e+00,  1.2545e-01,  3.2802e+00,\n",
       "           -1.5734e+00, -1.0913e+00, -9.3427e-01,  2.7638e-01,  1.1667e+00,\n",
       "           -2.6644e-02,  4.3226e-01, -1.5257e+00,  1.7812e+00, -1.1395e+00,\n",
       "           -1.3861e+00,  2.0941e+00, -1.0310e-01, -1.4798e+00,  1.3421e+00,\n",
       "           -1.2602e+00, -1.1528e+00,  4.6468e-02,  2.8449e-01,  2.3783e-02,\n",
       "            1.9443e+00,  2.5073e+00, -5.5642e-01,  6.2592e-01,  1.1903e+00,\n",
       "           -2.9745e+00, -8.6309e-01, -1.5293e-01,  1.3084e+00,  1.6437e-01,\n",
       "            8.0665e-01, -1.2921e+00,  1.1793e+00, -2.2467e-01,  1.5479e+00,\n",
       "           -2.8622e-02,  4.1158e-01, -1.2600e+00, -9.2926e-01, -6.2729e-01,\n",
       "            1.0810e+00, -5.0236e-01,  6.6239e-01, -1.2730e+00, -2.1588e-01,\n",
       "           -6.4763e-02,  5.4301e-01,  2.3815e-01, -1.1177e-03,  4.9839e-01,\n",
       "           -1.6286e+00,  2.4096e+00,  1.5916e+00,  1.9975e+00, -5.9396e-01,\n",
       "            1.7625e-01,  9.3047e-01, -2.9792e-01,  1.7758e+00, -2.5917e+00,\n",
       "            2.5529e+00,  1.9955e+00,  1.9030e+00, -2.1989e-01, -3.9272e-02,\n",
       "           -1.9186e-01,  1.3679e+00,  1.0395e+00, -1.4676e+00, -1.1421e+00,\n",
       "           -1.1869e+00, -1.1545e-01, -7.4598e-01,  4.7138e+00,  7.9539e-01,\n",
       "            1.1351e+00, -9.4906e-02,  6.0591e-01,  1.1114e+00, -2.3644e+00,\n",
       "            1.3046e-01,  1.4037e+00,  3.8210e-02, -9.6434e-01, -9.2018e-02,\n",
       "            1.1450e+00, -4.7944e-01,  2.0038e+00,  8.8099e-01, -2.0048e+00,\n",
       "           -1.2363e+00, -1.0678e+00,  4.6839e-01, -7.4538e-01, -1.0009e-01,\n",
       "           -5.7987e-01, -3.2489e-01,  1.0374e+00, -2.0094e+00,  2.1849e-01,\n",
       "            2.9176e+00, -7.6430e-01, -1.3287e-01, -2.0090e+00,  8.3490e-02,\n",
       "            9.9577e-01,  1.0433e-01,  1.6063e+00, -7.1259e-01,  8.9707e-02,\n",
       "            2.1096e+00,  1.9615e+00, -9.0293e-02,  1.5600e+00, -1.3129e+00,\n",
       "           -1.9370e+00,  3.9682e-01,  3.1263e-01, -1.0417e+00, -5.1700e-01,\n",
       "            1.7214e+00,  7.0186e-01,  1.8033e+00, -3.3713e-02, -1.2967e+00,\n",
       "            1.2526e-01,  9.1392e-01,  4.2508e-01,  1.1180e+00,  4.3817e-01,\n",
       "           -3.4540e-01, -8.7367e-01, -1.0863e+00, -1.0597e+00, -1.2324e+00,\n",
       "           -6.7539e-02,  6.3677e-02, -4.1905e+00,  3.2586e-01,  7.8375e-01,\n",
       "           -1.4804e+00, -7.3631e-01, -1.3981e+00, -1.0439e-01,  1.3175e+00,\n",
       "           -5.7198e-01,  3.7758e-01, -1.2321e+00, -1.7738e-01,  6.1231e-01,\n",
       "           -1.5192e+00,  2.5448e+00, -1.0457e+00, -9.0208e-01,  3.5334e-01,\n",
       "           -1.2474e+00,  3.1904e-01,  1.5025e+00,  6.5391e-01,  7.4437e-01,\n",
       "            1.3032e+00, -3.0857e-02, -4.1008e-01,  2.1407e+00, -9.2511e-02,\n",
       "           -3.9638e-01,  9.4372e-01,  4.3950e-01,  1.1826e+00,  5.4628e-01,\n",
       "            1.8200e+00, -6.2756e-01,  1.3050e+00, -7.9208e-01, -2.6479e+00,\n",
       "           -9.0486e-01,  1.7933e+00,  1.8033e-01,  8.9300e-01, -6.1666e-01,\n",
       "            5.1916e-01,  9.4582e-01, -1.4945e-01,  8.0700e-01, -3.6456e-02,\n",
       "           -4.6660e-01, -9.4798e-01, -4.3839e-01,  1.2662e+00, -1.0577e+00,\n",
       "           -1.3006e+00,  2.5039e+00, -2.2472e+00,  3.5332e-01, -3.2716e-02,\n",
       "            1.9974e-01,  1.0938e+00,  1.4935e-01, -3.4907e-01,  3.2572e+00,\n",
       "           -1.2769e-01,  2.6573e+00, -7.4198e-01,  2.0388e+00, -1.9436e+00,\n",
       "            6.6361e-01, -5.0983e-01, -3.1435e-01, -7.9379e-01, -6.4758e-01,\n",
       "            3.0156e+00, -4.0767e+00, -1.1003e+00, -5.2894e-01, -7.7723e-02,\n",
       "           -2.1339e+00, -1.0969e+00,  1.2051e-01,  4.7261e-01, -1.7702e+00,\n",
       "            7.9888e-02, -1.8909e-01,  7.0863e-01, -1.8369e+00,  4.2970e-01,\n",
       "           -8.1125e-01, -1.3407e-01, -2.7533e-01, -3.7757e-01, -8.3654e-01,\n",
       "            2.0708e+00, -6.4438e-01,  1.7977e+00, -1.9397e+00, -9.2484e-01,\n",
       "           -1.8350e+00, -6.7473e-01,  2.2434e+00, -4.9349e-01,  8.4936e-01,\n",
       "            1.6442e+00,  2.3540e+00, -1.1475e+00,  1.5357e+00,  1.3092e+00,\n",
       "           -1.2970e-01, -2.8410e-01,  1.3958e+00, -3.8489e-01, -1.3186e-01,\n",
       "           -6.0300e-01,  6.7732e-01,  1.4204e-01,  5.8953e-01,  3.9811e-01,\n",
       "           -1.5950e+00, -1.4287e+00, -1.1918e+00, -7.5282e-01,  5.2604e-01,\n",
       "            9.7253e-01,  1.6931e+00,  1.9404e-01, -3.2570e-01, -1.6104e+00,\n",
       "            1.8791e+00,  6.9105e-01,  6.6093e-02,  1.7490e-01,  2.8576e-01,\n",
       "           -1.3860e+00,  8.4277e-01,  3.9778e-01,  1.3468e-01,  2.1141e+00,\n",
       "            1.0034e+00,  3.0419e-01, -7.4554e-01,  2.9940e-01, -8.6732e-01,\n",
       "           -1.0258e-01,  8.1033e-01,  8.1667e-01, -2.7607e+00, -7.6173e-01,\n",
       "           -8.4069e-01,  1.0093e-01,  8.0282e-01,  9.2943e-01, -1.8564e+00,\n",
       "           -1.0786e+00, -3.1429e+00,  5.8434e-01,  1.2221e+00, -2.9394e-01,\n",
       "            1.9571e-03, -8.2961e-01, -2.1268e+00, -8.2066e-01,  2.6590e-01,\n",
       "           -2.8626e-01, -1.2311e+00,  1.7864e+00, -1.7729e+00,  5.4780e-01,\n",
       "            9.3838e-02,  1.2221e+00, -5.0116e-02, -2.6012e+00, -1.2965e+00,\n",
       "            9.1955e-01, -3.9550e-01, -1.4302e+00, -1.1304e+00, -4.6315e-01,\n",
       "           -1.1892e+00,  1.0453e+00, -1.6424e-01,  5.4626e-01, -3.4755e-01,\n",
       "           -3.8470e-01, -9.7528e-01, -1.5968e+00,  7.1793e-01,  2.2725e+00,\n",
       "            1.7248e+00,  7.1078e-01,  1.6457e-01, -7.3803e-01, -1.4147e-01,\n",
       "            7.2199e-01,  1.1883e+00,  1.3298e+00, -8.0691e-01,  9.2843e-02,\n",
       "            1.2546e+00,  1.3509e-01, -1.8096e+00, -9.1420e-01, -9.6573e-01,\n",
       "           -4.9418e-01, -2.3185e-01,  3.1773e+00, -3.4604e-01,  1.6878e-01,\n",
       "           -7.5449e-01, -9.2560e-02,  1.6658e+00,  1.0138e+00,  1.3866e+00,\n",
       "            8.3685e-01, -2.0275e-01, -3.2153e-01,  1.3618e+00, -1.3968e+00,\n",
       "           -2.2231e+00,  1.3015e-02, -2.6353e-01, -4.5660e-01,  7.2226e-01,\n",
       "           -9.3003e-01,  6.2903e-01, -2.1331e-01,  3.6511e-01,  1.0255e+00,\n",
       "            2.6392e-01,  2.8800e+00, -1.0300e+00, -4.7312e-01, -1.5742e+00,\n",
       "            1.8700e+00, -1.3706e+00, -6.2063e-01,  1.1803e+00, -3.4028e-01,\n",
       "           -1.8974e+00,  9.8607e-01,  1.7284e-01, -9.5503e-01,  2.2900e+00]),\n",
       "   'exp_avg_sq': tensor([ 55.3114,  81.0302,  20.4885,  53.2617,  35.7850,  39.7866,  20.8735,\n",
       "            48.1046,  22.3976,  35.5804,  64.5834,  26.7669,  39.7308,  30.0887,\n",
       "            63.9291,  55.1159,  62.4328,  39.1568,  41.4915,  43.9015,  35.1440,\n",
       "            40.4310,  28.3214,  46.3410,  24.9419,  30.5780,  28.5561, 133.3042,\n",
       "            35.8953,  27.1651,  32.2097,  62.1916,  25.1380, 112.2183,  79.7784,\n",
       "            29.1175,  76.5908,  23.0935,  24.5378,  33.2103,  51.5055,  56.5197,\n",
       "            53.3440,  28.6247,  39.3308,  29.0851,  85.2104,  33.0100,  60.1483,\n",
       "            46.0649,  34.6839,  43.3047,  21.4314,  68.5447,  22.9027,  34.6204,\n",
       "            65.2429,  66.3135,  26.9418,  45.9129,  54.3846,  57.4627,  30.7568,\n",
       "            44.4891,  35.0028,  43.3892,  39.3786,  28.0433,  36.4688,  42.8738,\n",
       "            50.1524,  25.3606,  38.6174,  64.8096,  29.2013,  45.8138,  50.0782,\n",
       "            23.6409,  35.9166,  37.5242,  35.6221,  35.4611,  54.7511,  63.5110,\n",
       "            29.3160,  12.6362,  11.9034,  39.2043,  21.6710,  23.6740,  30.1871,\n",
       "            47.5601,  39.9680,  69.0891,  55.8717,  28.6688,  38.9647,  20.4220,\n",
       "            35.7438,  37.6001,  14.7210,  51.5427,  39.5881,  39.0553,  18.0010,\n",
       "            49.5235,  48.2836,  33.1016,  32.2262,  49.3216,  43.2304,  48.5766,\n",
       "            51.7056,  13.6198,  52.6664,  44.9225,  45.9711,  22.3838,  43.7038,\n",
       "            26.0370,  48.9223,  20.2926,  36.3886,  46.2518,  19.5593,  47.8862,\n",
       "            52.8207,  49.6847,  44.1386,  30.9361,  44.7405,  20.8655,  24.1236,\n",
       "            33.4724,  37.3174,  56.6964,  12.3960,  63.4079,  25.7991,  47.6677,\n",
       "            73.3626,  24.2550,  40.0343,  29.5651,  81.0602,  24.9411,  34.2195,\n",
       "            32.2757,  32.6315,  64.6399,  22.8495,  43.5677,  23.7013,  45.0784,\n",
       "            46.0259,  66.4075,  53.9466,  77.6325,  30.4116,  48.5563,  36.2396,\n",
       "            31.4236,  25.9941,  59.3282,  50.9630,  20.0264,  32.2381,  59.3263,\n",
       "            44.0766,  62.4101,  37.8398,  28.1352,  43.1620,  52.3693,  84.8470,\n",
       "            30.0741,  49.3013,  40.3602,  21.3143,  65.2073,  39.9380,  64.3664,\n",
       "            53.6441,  38.1458,  59.9693,  32.1941,  50.6340,  34.8512,  31.1477,\n",
       "            42.4711,  35.9588,  35.5999,  33.6307,  12.0736,  45.9900,  34.3733,\n",
       "            49.5915,  31.5113,  20.0071,  31.5582,  27.0675,  16.4374,  32.0360,\n",
       "            35.5348,  63.0101,  49.3076,  37.0928,  30.6177,  51.2709, 158.4961,\n",
       "            33.6238,  18.3285,  48.6243,  22.0821,  28.8424,  33.9286,  47.9698,\n",
       "            33.9172,  18.6585,  20.1469,  36.3578,  42.8880,  23.9605,  26.5602,\n",
       "            38.9691,  26.2704,  33.2057,  20.3346,  35.2485,  29.2813,  57.8749,\n",
       "            76.8056,  17.5917,  24.6327,  32.0967,  41.5533,  64.7095,  65.1893,\n",
       "            34.0404,  39.0974,  28.3766,  67.9068,  48.0890,  33.1291,  33.6001,\n",
       "            25.7288,  21.5879,  56.4257,  32.4382,  52.5306,  51.5785,  44.5499,\n",
       "            80.3246,  41.8207,  33.9675,  33.9194,  63.1442,  51.4991,  23.4097,\n",
       "            50.5872,  49.6799,  54.3841,  30.2730,  55.7449,  23.7279,  35.3346,\n",
       "            17.8072,  31.2600,  24.5650,  34.7415,  35.3599,  19.9591,  73.8886,\n",
       "            54.6121,  21.6989, 101.1657,  59.1543,  30.5508,  54.0521,  69.0124,\n",
       "            51.2220,  22.8616,  28.0116,  70.3710,  57.4852,  56.2048,  38.2567,\n",
       "            41.8055,  43.0684,  16.9267,  28.7781,  53.7152,  40.1251,  34.4027,\n",
       "            70.9943,  49.1275,  51.9574,  32.8058,  34.7890,  26.6415,  22.4600,\n",
       "            52.7757,  51.9342,  44.1495,  59.5998,  25.6722,  18.4532,  26.7336,\n",
       "            22.6809,  96.0663,  45.0267,  61.8818,  43.7881,  19.8719,  36.1041,\n",
       "            38.6674,  36.1241,  16.6408,  41.4403,  43.4099,  29.9991,  76.8170,\n",
       "            23.4955,  58.3902,  42.3465,  46.5650,  19.9887,  53.5461,  51.4685,\n",
       "            15.1463,  50.1327,  22.7692,  44.7147,  59.2096,  55.3792,  27.3209,\n",
       "            33.3100,  31.6044,  32.5333,  42.8554,  27.1960,  25.8044,  41.3523,\n",
       "            42.8965,  36.1636,  40.4430,  21.0592,  29.4116,  24.6902,  41.0452,\n",
       "            44.9637,  62.4234,  64.4311,  43.0804,  30.7058,  25.5080,  44.3436,\n",
       "            63.0415,  43.9798,  54.7988,  41.9531,  30.0822,  47.6643,  50.8706,\n",
       "            40.1301,  22.6224,  46.5807,  39.6019,  25.8438,  37.0004,  25.7227,\n",
       "            51.2609,  21.5391,  21.0972,  39.7182,  44.5633,  31.4097,  35.1437,\n",
       "            68.7538,  28.2326,  35.2303,  51.6980,  34.4425,  63.8001,  28.9627,\n",
       "            18.4608,  44.7606,  42.8692,  23.2590,  31.9587,  43.6652,  71.1378,\n",
       "            19.4783,  49.9911,  43.2009,  33.2112,  31.4057,  46.3895,  56.4949,\n",
       "            63.6022])},\n",
       "  139626068042448: {'step': 5628,\n",
       "   'exp_avg': tensor([[1.7036e-04, 2.1514e-04, 8.8305e-05,  ..., 1.7476e-04, 2.0036e-04,\n",
       "            1.5211e-04],\n",
       "           [1.3809e-04, 1.7924e-04, 9.8038e-05,  ..., 1.3862e-04, 1.8920e-04,\n",
       "            1.1605e-04],\n",
       "           [1.7774e-04, 1.8685e-04, 1.1466e-04,  ..., 1.5380e-04, 1.9476e-04,\n",
       "            1.1807e-04],\n",
       "           ...,\n",
       "           [1.2557e-04, 1.9550e-04, 8.7787e-05,  ..., 1.1786e-04, 2.1033e-04,\n",
       "            1.1445e-04],\n",
       "           [1.1932e-04, 1.9364e-04, 7.4727e-05,  ..., 1.3184e-04, 1.8642e-04,\n",
       "            1.1228e-04],\n",
       "           [1.4800e-04, 1.7623e-04, 1.1147e-04,  ..., 1.9469e-04, 2.3919e-04,\n",
       "            1.5603e-04]]),\n",
       "   'exp_avg_sq': tensor([[0.0037, 0.0009, 0.0074,  ..., 0.0040, 0.0110, 0.0031],\n",
       "           [0.0027, 0.0008, 0.0072,  ..., 0.0031, 0.0100, 0.0026],\n",
       "           [0.0041, 0.0010, 0.0091,  ..., 0.0036, 0.0103, 0.0031],\n",
       "           ...,\n",
       "           [0.0029, 0.0007, 0.0063,  ..., 0.0031, 0.0102, 0.0020],\n",
       "           [0.0027, 0.0007, 0.0056,  ..., 0.0028, 0.0090, 0.0021],\n",
       "           [0.0031, 0.0008, 0.0102,  ..., 0.0042, 0.0132, 0.0040]])},\n",
       "  139626068042088: {'step': 5628,\n",
       "   'exp_avg': tensor([ 3.4518e-04,  2.9809e-04,  3.5658e-04,  2.9498e-04,  3.8435e-04,\n",
       "            3.1740e-04,  3.0450e-04,  3.9522e-04,  3.0757e-04,  3.1785e-04,\n",
       "            3.2620e-04,  3.5759e-04,  9.7955e-04,  2.5633e-03,  1.9993e-03,\n",
       "            3.8143e-04,  3.9786e-04,  3.4764e-04,  3.3197e-04,  2.8641e-04,\n",
       "            3.4740e-04,  3.0766e-04,  3.0970e-04,  3.1012e-04,  4.1639e-04,\n",
       "            3.0235e-04,  3.1905e-04,  3.9570e-04,  3.2608e-04,  3.0683e-04,\n",
       "            3.2418e-04,  3.3118e-04,  3.7940e-04,  7.4775e-04,  8.9003e-03,\n",
       "            1.4172e-02,  2.4280e-02,  1.5386e-02,  3.5105e-02,  2.2592e-02,\n",
       "            4.0903e-02,  5.8694e-02,  3.0134e-02,  5.1500e-02,  1.3164e-02,\n",
       "            2.0506e-02,  3.5557e-02,  1.9238e-02,  1.1935e-02,  1.9806e-02,\n",
       "            6.7015e-03,  1.5963e-03,  3.1587e-04,  3.5811e-04,  3.4749e-04,\n",
       "            3.3213e-04,  2.9264e-04,  3.4235e-04,  7.3464e-04,  5.7078e-04,\n",
       "            2.4576e-03, -1.0327e-03,  3.9821e-02,  6.4880e-02,  4.0745e-02,\n",
       "           -4.0696e-02,  4.9662e-02,  2.6031e-01,  2.2476e-01,  3.7978e-02,\n",
       "            3.5449e-02,  2.1376e-01,  1.9287e-01,  1.3863e-02,  7.8621e-02,\n",
       "           -8.8952e-02, -7.8065e-02, -3.4010e-03,  6.1451e-02,  2.1036e-02,\n",
       "            8.9425e-03,  4.2651e-03,  2.9377e-04,  3.8372e-04,  3.0569e-04,\n",
       "            3.5413e-04,  1.1044e-03,  1.6195e-03,  4.5638e-03,  2.3820e-02,\n",
       "            9.3233e-02,  4.5115e-02,  4.5988e-02, -4.8216e-02,  5.2366e-02,\n",
       "            2.8457e-01,  5.7055e-01,  3.8540e-01,  8.7117e-02,  6.7793e-02,\n",
       "           -9.4561e-02, -4.7124e-01, -5.6932e-01, -4.4785e-01, -2.4029e-01,\n",
       "           -1.1175e-01,  6.8912e-02,  4.1503e-02,  4.1969e-02,  8.9314e-03,\n",
       "            1.1275e-03,  3.4506e-04,  3.1858e-04,  6.3833e-04,  2.2341e-03,\n",
       "           -1.3153e-02, -1.1831e-02, -7.1385e-04,  4.1961e-02, -2.4015e-03,\n",
       "           -8.8020e-02, -2.0676e-01, -2.9030e-01,  1.7582e-01,  3.0995e-01,\n",
       "           -4.2387e-01, -1.5669e-01,  2.6861e-01, -2.6310e-01, -6.4456e-01,\n",
       "           -4.1267e-01, -1.6998e-01,  3.3879e-01,  2.3342e-01,  2.8408e-02,\n",
       "           -1.7447e-01, -4.9400e-02, -2.4163e-02, -7.0000e-03,  9.8069e-04,\n",
       "            2.6325e-04,  3.6470e-04,  1.8976e-03,  3.3804e-02,  4.5593e-02,\n",
       "           -2.0973e-02, -3.9384e-02, -1.4891e-01, -2.2557e-01,  4.0912e-01,\n",
       "            6.5025e-01,  7.7086e-01,  5.2330e-01,  5.6032e-01,  2.5781e-01,\n",
       "           -2.1985e-02, -5.4054e-02, -3.2482e-01,  3.0655e-01,  3.9799e-01,\n",
       "           -5.9877e-02,  2.2917e-01, -4.0879e-02, -3.0138e-01, -9.5698e-02,\n",
       "            1.2832e-02, -3.2264e-02,  2.2585e-03,  3.4436e-04,  4.2185e-04,\n",
       "            7.2141e-03,  3.3988e-02,  7.7795e-03,  5.5096e-02, -3.0111e-01,\n",
       "           -2.1071e-01, -3.9743e-03,  2.4592e-01,  2.5728e-01,  4.5652e-01,\n",
       "            7.0005e-01,  4.3503e-01,  3.8185e-01,  2.2270e-01,  6.0461e-02,\n",
       "            3.7524e-01,  3.6411e-01,  1.6115e-01, -4.6806e-01,  8.4271e-02,\n",
       "           -8.1397e-02, -1.4206e-02,  1.1889e-01,  5.9743e-02, -1.2006e-02,\n",
       "            1.6588e-02,  6.9703e-04,  6.3617e-03,  2.4260e-02,  7.8334e-02,\n",
       "            1.9417e-01,  2.3327e-01, -1.2812e-01,  2.8315e-01, -3.0107e-01,\n",
       "            3.7209e-01,  1.6505e-01, -8.3797e-02, -6.1390e-02, -9.1532e-02,\n",
       "            2.4026e-01,  4.2715e-01,  6.4826e-01,  1.2455e+00,  5.2541e-01,\n",
       "           -1.1603e-01, -6.2825e-01,  3.5175e-02, -6.9836e-01, -3.2950e-01,\n",
       "            6.1461e-02,  1.1632e-01, -2.5026e-02,  7.0843e-03,  2.0729e-03,\n",
       "            1.4410e-02,  4.6905e-02,  9.0555e-02,  1.8475e-01,  1.9904e-01,\n",
       "            3.7814e-01,  3.4400e-01, -3.2964e-01,  1.6490e-02, -1.1560e-01,\n",
       "            4.7946e-01,  1.7519e-01, -2.3224e-01, -2.6893e-01, -1.1424e-02,\n",
       "            9.5329e-01,  1.2096e+00, -2.4541e-01, -1.5120e-01, -3.0360e-01,\n",
       "            2.8739e-01, -2.2804e-01,  1.8371e-01,  3.6136e-01,  1.4323e-01,\n",
       "            2.5509e-02, -5.5437e-03,  1.7299e-03,  8.4596e-03, -1.6358e-01,\n",
       "            6.3165e-02,  2.7561e-01,  1.8389e-01,  1.1819e-01, -5.2066e-04,\n",
       "           -4.2213e-02, -2.9337e-02, -2.2874e-01,  1.0188e+00,  4.5251e-01,\n",
       "            1.5290e-01,  6.4501e-01,  2.4428e-01,  7.8489e-01,  1.6911e-01,\n",
       "           -2.2286e-01,  3.4056e-01,  4.7197e-01,  2.0550e-01,  1.9134e-01,\n",
       "            2.8775e-01,  3.1992e-01,  5.6954e-02,  5.9162e-02,  7.5958e-03,\n",
       "            2.2589e-03,  5.3074e-03, -2.0167e-01,  3.4282e-02,  2.3180e-01,\n",
       "            4.6414e-02,  1.2018e-01,  7.9931e-02,  3.5053e-01,  3.3365e-01,\n",
       "            3.8889e-01,  9.5747e-01,  3.0250e-01, -2.8210e-01, -4.6845e-01,\n",
       "            1.5609e-01,  1.0441e+00, -3.6019e-02, -3.6437e-01,  5.4020e-01,\n",
       "            1.0913e-01, -1.4896e-01, -1.5778e-01, -8.2606e-02,  1.2553e-01,\n",
       "           -3.0990e-03,  3.8326e-03,  4.9171e-03,  2.2952e-03,  3.6411e-02,\n",
       "           -9.4344e-02,  1.8444e-02,  1.3956e-01, -1.2111e-01, -1.5662e-01,\n",
       "           -1.7306e-01,  3.7235e-02,  2.8557e-01,  7.1766e-01,  8.2032e-02,\n",
       "           -3.2795e-01, -5.1675e-01, -5.5029e-02,  3.5419e-01,  7.1242e-01,\n",
       "           -1.7222e-01,  6.7161e-02,  1.0343e+00,  3.7638e-01,  1.3329e-01,\n",
       "            1.3173e-01, -9.1567e-02,  4.6715e-02,  3.4793e-02, -4.2136e-03,\n",
       "            2.9869e-03,  2.0242e-03,  2.4323e-02, -1.5060e-02, -4.4552e-02,\n",
       "           -1.5431e-01, -3.9719e-01,  5.2555e-02, -2.4140e-01, -6.1961e-01,\n",
       "           -4.9441e-01, -1.1929e-01, -2.6258e-01,  2.3307e-01,  5.3844e-02,\n",
       "            5.8747e-02,  1.7890e-01,  4.9026e-01,  8.1529e-01,  5.4689e-01,\n",
       "            4.5280e-01, -3.3151e-01,  2.1924e-01,  4.7727e-01, -1.6024e-01,\n",
       "           -3.3206e-01,  6.7060e-02,  2.6285e-02,  3.2566e-03,  5.9943e-04,\n",
       "            1.7439e-03, -9.2618e-02, -4.0554e-02, -5.6296e-02,  1.7231e-01,\n",
       "           -4.6806e-02, -2.5036e-01, -4.7416e-01, -7.4608e-01, -1.3811e+00,\n",
       "           -7.9294e-01, -1.9008e-01, -9.4114e-02, -4.8124e-02, -7.0736e-01,\n",
       "            9.3516e-03,  3.1358e-01,  1.2160e+00, -1.5913e-01, -5.3050e-01,\n",
       "           -2.0874e-01,  3.4374e-01, -7.8850e-02, -3.0916e-01,  1.1031e-01,\n",
       "           -3.8657e-03,  3.9488e-03,  9.9889e-04, -2.8579e-03, -1.0443e-01,\n",
       "           -1.0079e-02,  1.0053e-01, -1.4929e-01, -2.2111e-01,  6.8783e-02,\n",
       "           -4.0417e-01, -1.1141e+00, -1.5338e+00, -6.7843e-01, -8.3986e-01,\n",
       "           -5.7648e-01, -5.8744e-01, -9.3723e-01, -1.1940e-01,  3.8240e-01,\n",
       "           -3.1049e-02,  5.8426e-01, -4.3923e-01, -1.8389e-01,  3.7791e-01,\n",
       "           -1.8621e-01, -2.2125e-01,  4.5638e-02,  1.0247e-02,  1.2200e-03,\n",
       "            5.5401e-04,  2.0206e-03,  7.4388e-03,  9.6314e-03, -1.2691e-02,\n",
       "           -6.3787e-02, -2.0583e-01,  7.5704e-02,  1.6353e-02,  8.2873e-02,\n",
       "           -4.0363e-01, -1.4022e-01, -2.7809e-01,  3.2443e-01,  8.1668e-01,\n",
       "           -3.9766e-01, -6.9038e-01,  1.4750e-01, -8.1267e-02,  3.5734e-01,\n",
       "            2.0738e-01,  6.7105e-02,  1.3350e-01, -5.8175e-02,  9.8631e-02,\n",
       "            2.2410e-01,  3.1182e-02,  5.0079e-03,  5.6221e-04,  1.2557e-03,\n",
       "            9.4723e-03,  5.2104e-02,  2.0926e-01,  4.9546e-02, -1.1651e-01,\n",
       "           -2.5835e-01,  1.5270e-01,  1.1693e+00,  1.1496e+00,  4.3938e-01,\n",
       "            5.6069e-01,  6.3168e-01,  5.3647e-01,  1.1961e-01, -1.7262e-01,\n",
       "            7.6593e-01, -4.6586e-01, -4.4059e-01,  6.6351e-01,  6.5685e-01,\n",
       "            3.7105e-01,  2.4841e-01,  1.5493e-01,  2.5115e-01,  5.5866e-03,\n",
       "            6.2930e-03,  3.8407e-04, -8.0255e-03,  1.3172e-02,  4.3737e-02,\n",
       "            1.5158e-01,  6.8137e-01,  2.6282e-01, -3.2449e-01,  4.2604e-02,\n",
       "            8.4921e-01,  1.0890e-03, -3.3691e-01, -1.4700e-01,  6.6000e-01,\n",
       "            7.0615e-01,  1.0322e+00,  2.3131e-01,  4.6899e-01, -4.0349e-01,\n",
       "           -3.9224e-01,  1.1650e-01,  1.4260e-01, -8.2802e-02, -1.3977e-01,\n",
       "            6.1695e-02,  1.1350e-01,  6.6268e-02,  6.6819e-03,  1.5191e-03,\n",
       "            1.0872e-03,  6.6683e-03,  3.2387e-02,  1.3314e-01,  2.1420e-01,\n",
       "            6.2206e-03, -8.8524e-01, -1.7760e-01,  5.7884e-01, -6.3886e-01,\n",
       "           -2.8961e-01,  4.7094e-01,  7.0263e-01,  2.0125e-01,  6.8789e-01,\n",
       "            4.0963e-01, -8.4518e-02, -1.7202e-01, -8.2559e-01, -1.3659e-01,\n",
       "            4.3849e-01,  6.6464e-02, -1.2197e-01, -6.7791e-02, -8.4807e-03,\n",
       "            5.8768e-02,  4.2694e-03,  4.0232e-04,  4.0053e-03, -1.7027e-02,\n",
       "           -6.6552e-02,  1.2664e-01,  1.6562e-03, -7.6929e-01, -4.9990e-01,\n",
       "           -3.8181e-01,  4.5787e-01, -6.1103e-01, -1.6369e-01,  3.0944e-01,\n",
       "            2.5736e-01,  8.6222e-02,  3.4779e-01,  3.2795e-01, -6.7254e-02,\n",
       "            2.5251e-02, -4.6778e-01,  2.6116e-02,  8.0713e-01,  7.2518e-01,\n",
       "            1.1141e-01,  5.0230e-02,  2.1551e-02,  3.5986e-02,  2.4680e-03,\n",
       "            3.3850e-04,  3.9149e-03, -7.0199e-02, -3.2180e-03,  2.8678e-01,\n",
       "            2.2596e-02, -6.8640e-01, -3.7557e-01,  1.6989e-01,  3.4855e-01,\n",
       "            4.2799e-01,  6.0932e-01,  9.1346e-01,  3.4162e-01,  7.7072e-01,\n",
       "            2.2504e-01,  1.8275e-02, -3.5269e-02, -1.9124e-01, -3.9772e-01,\n",
       "            1.1908e-01,  4.2347e-01,  6.5855e-01,  2.5996e-01,  2.3929e-01,\n",
       "            1.6605e-01,  3.7344e-02,  1.0480e-03,  5.1953e-04,  4.0524e-03,\n",
       "           -6.8801e-02, -2.1502e-03,  1.7789e-01,  1.2613e-01, -7.0629e-01,\n",
       "           -6.5898e-01, -2.1074e-02, -1.3260e-01,  3.5689e-01,  4.7874e-01,\n",
       "            1.1213e-01,  6.4514e-01,  6.2590e-01, -6.6623e-01, -1.1675e+00,\n",
       "           -6.9638e-01, -2.3067e-01, -2.0245e-02, -4.4192e-01, -1.9502e-01,\n",
       "            3.5472e-01,  4.7740e-01,  1.9180e-01,  5.7799e-02,  2.9940e-02,\n",
       "            5.9736e-04,  5.6586e-04,  7.2679e-04,  8.2026e-02,  9.5444e-02,\n",
       "            1.4048e-01, -1.1909e-02, -6.3675e-02, -2.9718e-01, -2.4048e-01,\n",
       "           -6.0310e-01, -1.3789e-01,  3.5537e-01,  4.0158e-01,  8.8393e-01,\n",
       "            6.5883e-01, -6.4668e-01, -8.5676e-01, -6.5181e-01, -2.9293e-01,\n",
       "            1.4215e-01,  4.3277e-02, -1.0302e-02, -2.9987e-02,  2.1903e-01,\n",
       "            7.0248e-02, -1.5304e-02,  7.1918e-03,  8.9305e-04,  3.1333e-04,\n",
       "            3.6995e-04,  6.6497e-02,  2.8128e-02, -1.9706e-01, -1.4191e-01,\n",
       "           -4.5005e-02,  2.1218e-01, -3.1920e-01, -7.9945e-01, -4.6614e-01,\n",
       "           -3.0955e-02,  2.4872e-01,  5.4776e-01,  7.9325e-01, -5.2020e-01,\n",
       "           -1.1384e-01, -1.4276e-01,  3.7390e-01,  7.5599e-01,  1.9151e-01,\n",
       "           -1.5458e-01, -1.8948e-01, -1.4056e-01, -6.4127e-02, -8.6893e-02,\n",
       "           -1.0964e-03,  3.4137e-04,  3.1113e-04,  3.1086e-04,  6.4370e-03,\n",
       "            3.4265e-02, -4.2848e-02, -7.6528e-02, -5.6660e-02, -5.4544e-02,\n",
       "            5.7936e-02, -4.2895e-01, -5.1717e-01, -1.3586e-01, -3.3979e-01,\n",
       "            1.7455e-01,  5.5142e-01, -3.1574e-01,  5.0266e-01,  3.6665e-01,\n",
       "            2.5294e-01,  1.4167e-01,  1.0087e-02, -1.2261e-01, -2.3383e-01,\n",
       "           -1.9154e-01, -8.3292e-02, -5.3408e-02,  1.1133e-03,  3.0943e-04,\n",
       "            3.0451e-04,  2.9053e-04,  9.6908e-04,  3.4783e-03, -1.4554e-02,\n",
       "           -1.4783e-02, -1.7597e-01, -1.7618e-01, -4.5619e-02, -2.8901e-01,\n",
       "            2.6035e-02,  5.6547e-01,  7.9757e-02, -1.4938e-02,  4.2121e-01,\n",
       "            1.5133e-01,  1.6654e-01,  3.7453e-02,  2.9092e-02,  7.8464e-02,\n",
       "            1.5172e-01,  2.9346e-02, -8.8847e-02, -2.2771e-02,  4.4496e-03,\n",
       "            1.6488e-03,  1.0767e-03,  3.3035e-04,  3.3632e-04,  3.4723e-04,\n",
       "            3.4806e-04,  5.5148e-04,  8.4942e-03,  1.2069e-02,  4.4825e-02,\n",
       "            2.6419e-02,  2.7255e-03, -1.9066e-01,  7.9368e-02,  5.8505e-02,\n",
       "            8.7779e-02,  1.0490e-01,  1.2477e-01,  1.3985e-01, -8.8928e-02,\n",
       "            1.7881e-02,  2.1501e-01,  6.7375e-02, -6.2703e-03,  3.7979e-03,\n",
       "            2.0210e-02, -1.0507e-02,  5.5629e-04,  8.5597e-04,  3.6316e-04,\n",
       "            3.5303e-04,  3.0819e-04,  3.1336e-04,  3.2642e-04,  2.9146e-04,\n",
       "            1.5325e-03,  3.6425e-03,  5.7165e-03,  1.1598e-02, -2.8840e-02,\n",
       "           -4.8819e-02, -1.7745e-02,  6.9341e-03,  1.9056e-02,  7.7691e-03,\n",
       "            2.4984e-02,  4.8188e-02, -5.6856e-02, -3.5636e-02,  4.8229e-02,\n",
       "            1.9592e-02,  7.5363e-03,  4.3778e-03,  3.1985e-03,  5.3290e-05,\n",
       "            3.1470e-04,  3.1370e-04,  3.1456e-04,  3.6928e-04]),\n",
       "   'exp_avg_sq': tensor([ 0.0850,  0.0678,  0.0852,  0.0670,  0.0996,  0.0731,  0.0689,  0.1097,\n",
       "            0.0728,  0.0669,  0.0728,  0.0971,  0.0606,  0.0843,  0.1091,  0.0869,\n",
       "            0.1124,  0.0839,  0.0823,  0.0680,  0.0828,  0.0699,  0.0672,  0.0713,\n",
       "            0.1081,  0.0635,  0.0715,  0.1061,  0.0801,  0.0653,  0.0806,  0.0808,\n",
       "            0.0694,  0.0878,  0.0732,  0.0654,  0.0942,  0.0692,  0.1148,  0.1200,\n",
       "            0.1013,  0.1294,  0.1291,  0.1422,  0.1388,  0.0918,  0.1091,  0.0999,\n",
       "            0.0871,  0.0919,  0.0922,  0.0895,  0.0768,  0.0963,  0.0815,  0.0757,\n",
       "            0.0628,  0.0839,  0.0657,  0.0641,  0.0706,  0.0682,  0.0643,  0.1052,\n",
       "            0.1506,  0.2245,  0.2845,  0.3287,  0.4334,  0.5296,  0.5928,  0.6987,\n",
       "            0.6661,  0.6202,  0.5757,  0.4858,  0.3025,  0.2515,  0.1696,  0.1060,\n",
       "            0.0715,  0.0822,  0.0731,  0.0983,  0.0656,  0.0892,  0.0524,  0.0681,\n",
       "            0.1359,  0.1216,  0.1811,  0.2075,  0.2690,  0.4871,  0.6318,  0.7914,\n",
       "            1.0161,  1.2376,  1.6004,  1.7235,  1.7323,  1.4789,  1.3004,  1.0755,\n",
       "            0.7210,  0.5266,  0.3090,  0.1874,  0.1674,  0.1070,  0.0969,  0.0850,\n",
       "            0.0714,  0.1153,  0.0826,  0.1093,  0.0760,  0.1989,  0.3186,  0.5061,\n",
       "            0.8052,  1.2232,  1.6943,  2.3994,  3.0757,  3.6688,  4.6074,  5.3399,\n",
       "            5.1547,  4.4964,  3.7926,  3.0368,  2.2493,  1.4761,  0.9590,  0.5914,\n",
       "            0.3296,  0.1522,  0.1241,  0.0885,  0.0526,  0.0949,  0.1237,  0.1080,\n",
       "            0.1907,  0.3878,  0.6461,  1.0565,  1.6134,  2.4628,  3.3303,  4.5457,\n",
       "            5.5753,  6.2632,  6.9149,  7.6870,  7.5995,  7.0490,  6.1871,  5.4472,\n",
       "            4.2194,  3.0258,  2.0620,  1.2193,  0.6962,  0.3362,  0.1411,  0.0817,\n",
       "            0.0808,  0.0919,  0.0778,  0.1769,  0.3645,  0.6813,  1.1067,  1.8720,\n",
       "            2.6166,  3.7825,  5.0058,  6.2342,  6.7849,  7.7210,  8.3537,  7.8911,\n",
       "            8.5542,  8.3446,  7.6991,  7.0129,  5.3564,  4.0457,  2.6631,  1.6770,\n",
       "            1.0563,  0.4903,  0.1795,  0.0919,  0.0728,  0.1011,  0.1295,  0.2570,\n",
       "            0.5177,  0.9294,  1.6207,  2.6042,  3.6351,  4.9150,  6.9351,  8.0357,\n",
       "            8.2592,  8.9076,  8.9370,  8.6372,  9.3966,  9.7689,  9.4804,  8.9548,\n",
       "            6.6792,  4.7742,  2.9609,  1.9244,  1.1621,  0.6004,  0.2108,  0.0657,\n",
       "            0.0973,  0.1139,  0.1694,  0.3298,  0.7123,  1.2164,  1.8331,  2.8628,\n",
       "            4.3752,  5.8975,  7.0123,  7.7671,  8.4355,  8.6482,  8.5707,  8.6533,\n",
       "            9.2223, 10.2011,  9.3532,  8.9031,  6.7179,  4.6578,  3.1182,  1.9407,\n",
       "            1.2199,  0.5791,  0.2098,  0.0955,  0.0766,  0.1863,  0.1647,  0.3809,\n",
       "            0.7860,  1.3850,  2.0807,  3.1482,  4.7766,  6.1850,  7.3180,  7.6744,\n",
       "            8.1220,  7.5728,  7.3637,  7.6612,  8.7768,  8.5261,  8.8867,  8.4898,\n",
       "            6.5522,  4.4816,  2.9516,  1.8616,  0.9772,  0.4598,  0.1736,  0.0953,\n",
       "            0.0759,  0.0860,  0.1758,  0.3580,  0.6832,  1.2178,  2.0866,  3.3712,\n",
       "            4.9090,  6.1510,  7.1854,  7.8944,  7.7607,  7.4085,  6.5814,  7.4206,\n",
       "            7.8395,  8.2004,  8.3690,  7.7393,  5.8892,  3.9786,  2.5698,  1.6816,\n",
       "            0.8370,  0.3383,  0.1345,  0.0644,  0.0882,  0.1155,  0.1535,  0.2961,\n",
       "            0.5877,  1.1195,  2.0051,  3.4650,  4.8201,  6.2937,  7.5880,  7.8013,\n",
       "            7.6677,  7.1219,  6.2552,  6.7666,  7.5199,  7.8191,  8.5495,  7.1815,\n",
       "            5.4846,  3.5615,  2.1645,  1.3670,  0.7555,  0.1964,  0.1795,  0.0869,\n",
       "            0.0881,  0.0730,  0.1324,  0.2762,  0.5584,  1.0828,  2.1088,  3.5843,\n",
       "            4.8578,  6.1735,  7.1879,  7.6189,  7.7206,  7.3601,  6.6279,  7.2664,\n",
       "            8.3212,  8.5901,  8.0586,  6.7992,  5.1453,  3.4692,  2.0824,  1.2393,\n",
       "            0.7640,  0.2278,  0.1122,  0.0892,  0.1008,  0.0740,  0.0956,  0.2121,\n",
       "            0.5054,  1.2057,  2.2098,  3.8548,  5.1882,  6.6149,  7.2370,  7.3982,\n",
       "            7.7387,  7.9960,  7.5458,  8.8145,  9.3377,  8.7880,  8.1103,  6.9105,\n",
       "            5.2074,  3.4104,  2.1917,  1.3024,  0.7737,  0.2397,  0.1218,  0.1062,\n",
       "            0.0835,  0.0756,  0.0743,  0.1886,  0.5981,  1.3209,  2.4616,  4.0550,\n",
       "            5.4867,  6.8828,  7.6046,  8.3473,  8.8617,  8.6225,  8.2556,  9.3648,\n",
       "            9.7090,  8.1575,  7.4466,  6.8765,  5.0965,  3.5196,  2.2900,  1.4236,\n",
       "            0.8596,  0.3044,  0.1081,  0.0931,  0.0925,  0.0550,  0.0980,  0.2110,\n",
       "            0.6408,  1.6160,  2.8099,  4.2380,  5.7602,  7.0053,  8.1998,  9.1089,\n",
       "            9.7246,  8.9838,  8.6022,  9.8606,  9.5247,  8.5402,  7.8066,  6.6167,\n",
       "            4.9728,  3.5522,  2.3668,  1.4912,  0.9183,  0.3228,  0.1214,  0.0884,\n",
       "            0.0943,  0.0935,  0.1092,  0.2282,  0.7470,  1.7846,  2.9233,  4.3928,\n",
       "            5.7594,  7.2775,  7.6452,  8.2268,  7.9636,  8.0148,  8.3953,  9.3773,\n",
       "            8.3404,  8.0658,  7.7705,  6.3688,  5.0578,  3.5863,  2.5515,  1.5260,\n",
       "            0.8621,  0.3629,  0.1192,  0.1190,  0.1109,  0.0612,  0.1329,  0.2830,\n",
       "            0.8842,  1.9821,  2.8794,  4.2595,  5.6695,  6.3633,  6.8215,  7.3473,\n",
       "            7.2048,  7.9664,  7.7362,  8.2001,  8.0280,  8.2347,  7.4845,  5.7865,\n",
       "            4.8042,  3.4413,  2.4958,  1.5888,  0.8975,  0.4000,  0.1530,  0.1076,\n",
       "            0.0856,  0.1099,  0.1274,  0.3862,  1.0199,  1.9485,  3.1702,  4.4275,\n",
       "            5.2233,  5.4345,  6.2243,  6.5239,  6.9249,  7.3039,  7.7753,  7.9509,\n",
       "            8.1094,  7.7740,  6.8600,  5.5622,  4.2689,  3.2653,  2.3483,  1.6265,\n",
       "            0.9024,  0.3626,  0.0980,  0.0770,  0.0731,  0.1004,  0.1711,  0.4466,\n",
       "            1.1329,  2.0843,  3.2015,  4.6067,  5.4983,  5.7355,  6.1852,  6.0749,\n",
       "            6.7659,  7.4793,  7.4739,  7.7606,  7.9076,  7.0394,  6.3481,  5.1952,\n",
       "            4.0432,  3.0046,  2.1639,  1.3548,  0.6899,  0.3451,  0.1432,  0.0966,\n",
       "            0.0847,  0.0918,  0.1598,  0.4904,  1.0958,  2.1188,  3.4083,  4.2653,\n",
       "            5.5079,  5.8710,  6.5613,  6.9697,  7.1213,  7.6793,  7.6449,  7.8025,\n",
       "            7.7651,  6.5764,  6.1618,  4.7244,  3.5644,  2.7253,  1.8023,  1.1144,\n",
       "            0.6191,  0.2532,  0.1260,  0.0626,  0.0835,  0.0674,  0.1898,  0.4303,\n",
       "            1.0573,  1.9101,  3.2442,  4.2957,  5.5559,  6.1514,  7.0262,  7.0867,\n",
       "            7.2907,  8.1708,  8.1008,  7.8380,  7.7276,  6.0318,  5.0902,  3.9160,\n",
       "            2.6696,  1.8915,  1.1958,  0.8409,  0.5215,  0.2003,  0.0997,  0.0799,\n",
       "            0.0994,  0.0824,  0.1685,  0.3463,  0.8118,  1.5834,  2.5922,  3.8299,\n",
       "            5.4160,  6.2964,  6.7199,  6.9301,  7.5901,  7.8155,  7.3614,  6.6434,\n",
       "            6.0657,  5.0287,  3.9650,  2.7407,  2.0176,  1.3572,  0.8152,  0.5179,\n",
       "            0.2875,  0.0996,  0.0746,  0.0963,  0.0784,  0.0935,  0.0844,  0.1646,\n",
       "            0.4277,  0.9338,  1.6503,  2.9325,  4.2400,  5.4617,  6.1186,  6.5317,\n",
       "            7.0386,  6.8470,  6.7058,  5.8838,  4.8225,  3.8535,  2.8659,  1.9297,\n",
       "            1.3569,  0.8851,  0.5392,  0.2892,  0.1757,  0.1209,  0.0672,  0.0872,\n",
       "            0.0717,  0.0754,  0.0736,  0.1328,  0.2346,  0.3897,  0.8632,  1.4398,\n",
       "            2.2252,  2.8401,  3.7333,  4.2883,  4.6103,  4.5218,  4.4608,  3.9213,\n",
       "            3.0387,  2.1919,  1.5704,  1.1039,  0.7153,  0.4852,  0.2636,  0.2096,\n",
       "            0.1005,  0.0722,  0.0853,  0.0746,  0.0627,  0.0617,  0.1087,  0.0630,\n",
       "            0.1194,  0.1959,  0.2907,  0.4869,  0.8253,  1.2535,  1.5930,  1.8696,\n",
       "            1.9462,  1.9601,  1.8493,  1.6834,  1.2932,  1.0598,  0.8114,  0.5708,\n",
       "            0.4074,  0.2802,  0.1800,  0.1429,  0.0946,  0.0774,  0.1235,  0.0816,\n",
       "            0.0850,  0.0859,  0.0903,  0.0794,  0.1282,  0.1096,  0.1899,  0.2549,\n",
       "            0.3970,  0.5456,  0.8808,  0.8621,  0.9016,  0.8409,  0.8528,  0.6944,\n",
       "            0.6441,  0.4681,  0.3718,  0.2895,  0.1880,  0.1504,  0.0993,  0.0936,\n",
       "            0.0790,  0.1339,  0.0899,  0.0984,  0.0735,  0.0760,  0.0814,  0.0672,\n",
       "            0.0647,  0.1033,  0.0981,  0.0691,  0.1398,  0.1090,  0.1285,  0.1745,\n",
       "            0.1979,  0.1728,  0.1966,  0.2078,  0.2154,  0.1340,  0.1239,  0.0942,\n",
       "            0.0708,  0.0808,  0.0805,  0.0827,  0.0729,  0.0719,  0.0669,  0.0870])}},\n",
       " 'param_groups': [{'lr': 0.001,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'params': [139626076512192,\n",
       "    139626076509096,\n",
       "    139626076558320,\n",
       "    139626076560048,\n",
       "    139626076558896,\n",
       "    139626076559040,\n",
       "    139626076559328,\n",
       "    139626076559472,\n",
       "    139626068042448,\n",
       "    139626068042088]}]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({ \n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "d =torch.load(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
